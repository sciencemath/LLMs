{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b00c36-3cbb-41a1-8c4e-e468cde0206c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./.venv/lib/python3.11/site-packages (4.47.1)\n",
      "Requirement already satisfied: accelerate in ./.venv/lib/python3.11/site-packages (1.2.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in ./.venv/lib/python3.11/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from transformers) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.11/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./.venv/lib/python3.11/site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"transformers\" \"accelerate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "668428f3-df70-4058-927b-411f39951e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed6c61e2d9e4dc3b4ae87a1b95279f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d89ee36ca844dbfa6e2f59e0eb89901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c349ee5a9c5249d3914d8d80a2b1093f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad9b5655ffc4be4964932c049d6f5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e491af63fb894b3ca9000d2687b95de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1fa7eac62542bcb970c2d89dea8202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235e37fc771941fea48acc8e3351942d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00eaecd46f24363afaccd7300e6f141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd2f6376fbd4a5daecbea10faf89ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5862cc44e93409ea3d59003a8c5a8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22247e1a299c476982f03e67bcff486d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from unittest.mock import patch\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.dynamic_module_utils import get_imports\n",
    "\n",
    "\n",
    "def fixed_get_imports(filename: str | os.PathLike) -> list[str]:\n",
    "    \"\"\"Work around for https://huggingface.co/microsoft/phi-1_5/discussions/72.\"\"\"\n",
    "    imports = get_imports(filename)\n",
    "    if not torch.cuda.is_available() and \"flash_attn\" in imports:\n",
    "        imports.remove(\"flash_attn\")\n",
    "    return imports\n",
    "\n",
    "with patch(\"transformers.dynamic_module_utils.get_imports\", fixed_get_imports):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=\"auto\",\n",
    "        attn_implementation=\"eager\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf923d8e-8d8b-4d09-8629-caa6bf99d253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=500,\n",
    "    do_sample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d1bba67-9034-4ff0-ae82-4f6efa06ed70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Why don't squids play hide and seek?\n",
      "\n",
      "Because good luck hiding when you're the star of Squid Games!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Create a funny joke about Squid Games.\"}\n",
    "]\n",
    "\n",
    "output = generator(messages)\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea17fa67-d18a-4bb1-94f4-c133c7cc1b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write an email apologizing to Mathias for eating his lunch. Explain how it happened.<|assistant|> Subject: Sincere Apologies for Eating Your Lunch\n",
      "\n",
      "Dear Mathias\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write an email apologizing to Mathias for eating his lunch. Explain how it happened.<|assistant|>\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"mps\")\n",
    "\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=20\n",
    ")\n",
    "print(tokenizer.decode(generation_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01f5f595-e6a9-4367-834f-ad4fc57ab26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write\n",
      "an\n",
      "email\n",
      "apolog\n",
      "izing\n",
      "to\n",
      "Math\n",
      "ias\n",
      "for\n",
      "e\n",
      "ating\n",
      "his\n",
      "l\n",
      "unch\n",
      ".\n",
      "Exp\n",
      "lain\n",
      "how\n",
      "it\n",
      "happened\n",
      ".\n",
      "<|assistant|>\n"
     ]
    }
   ],
   "source": [
    "for id in input_ids[0]:\n",
    "    print(tokenizer.decode(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6309dfda-ad32-49dc-bfe3-22bf48bd3c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cf7884cb2f4d24a90d438d3662afd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf10c6c8023e42ecafaf9c7a70e36b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be7cc83085f41769b9edc94b419ff86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740fd2f25399400091d0c8c2e9ea0d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba044b41-6b71-4785-878a-10fdb84ce731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018e857ccb2c4e3a998e2d3972ac3a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73b2aa22cae4d838e5d26d54bb09545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained('microsoft/deberta-v3-xsmall')\n",
    "tokens = tokenizer('The answer to everything is 42', return_tensors='pt')\n",
    "output = model(**tokens)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3033695-5c2c-4734-a24b-4e8274eb51e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.3034e+00, -1.3611e-01,  7.7370e-03,  ..., -8.9477e-02,\n",
       "          -4.0026e-01,  2.0351e-01],\n",
       "         [ 1.4900e-01,  1.9346e-01,  1.3302e-01,  ..., -5.9063e-02,\n",
       "          -1.5275e-04, -9.9055e-01],\n",
       "         [-3.1421e-01,  3.9509e-01,  1.2259e-01,  ..., -3.9398e-02,\n",
       "          -5.1547e-01, -7.0252e-01],\n",
       "         ...,\n",
       "         [-1.2463e+00,  3.4301e-01,  1.5588e-01,  ...,  3.2109e-01,\n",
       "          -1.8537e-02, -5.5037e-03],\n",
       "         [-3.4291e-01, -8.9625e-02, -2.6710e-01,  ..., -6.7299e-01,\n",
       "          -4.4655e-01, -4.8536e-01],\n",
       "         [-3.0789e+00,  2.6972e-01,  4.3562e-02,  ..., -2.6193e-01,\n",
       "          -5.3166e-01, -3.1264e-01]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5061591a-33b1-4aba-bb32-feeba3121e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 384])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ce1767f-da22-433e-8670-96b217ff7c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\n",
      "The\n",
      " answer\n",
      " to\n",
      " everything\n",
      " is\n",
      " 42\n",
      "[SEP]\n"
     ]
    }
   ],
   "source": [
    "for token in tokens['input_ids'][0]:\n",
    "    print(tokenizer.decode(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ddd7f46-c646-47a5-bb04-d6e2b5434ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (4.47.1)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (1.6.0)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (1.15.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (0.27.1)\n",
      "Collecting Pillow (from sentence_transformers)\n",
      "  Downloading pillow-11.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.12.14)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Downloading pillow-11.1.0-cp311-cp311-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: Pillow, sentence_transformers\n",
      "Successfully installed Pillow-11.1.0 sentence_transformers-3.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sentence_transformers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c463c362-9aa0-469d-af1f-d7034281cf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da51cb4a7fee4bf8b08cbf3706401e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b710e0dab9470481a3cece1690019d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02287cfa422d4a2a92b91dfef700ae04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98cd665ee2242a8b8ae43082242a996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b1f39a27ed4f80a15d80b3323bc790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63bf4c1d99b453d9964cb5fedf19a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8f9fdfa81a40f780c9237fbbb8ea34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f231a0ec8042d589356d52b8614ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8401ca58126b461dbefd55f47d918fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1603b170f3874d43a44efb658045c69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7119c2e324d24c72afeace2c125be82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "vector = model.encode(\"You can run fast!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6ae196c-4bf5-4946-ba52-0ffaeb0d857a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.75788175e-02,  4.18258496e-02, -3.12561952e-02,  5.04651479e-02,\n",
       "        7.14919418e-02,  3.05077676e-02, -2.70160791e-02,  4.89523783e-02,\n",
       "       -1.02532497e-02, -1.01752169e-02, -3.73260374e-03,  6.42043306e-03,\n",
       "       -3.22167464e-02,  5.52268475e-02,  3.02441306e-02, -6.22370541e-02,\n",
       "        1.22366389e-02, -5.97827248e-02,  6.02886602e-02,  4.04265244e-03,\n",
       "        5.83045706e-02, -1.32668959e-02,  1.25319771e-02, -9.10135079e-03,\n",
       "       -2.42285784e-02, -3.40190642e-02,  3.43343839e-02,  3.66259762e-03,\n",
       "       -5.92255825e-03, -4.56817038e-02, -4.17692214e-02, -2.32958477e-02,\n",
       "        2.23593581e-02,  3.04565728e-02,  2.00352883e-06, -9.76666436e-03,\n",
       "        3.65819335e-02,  2.36225948e-02, -5.48911579e-02,  3.21304165e-02,\n",
       "        3.08987368e-02, -3.30057251e-03, -5.75894900e-02,  4.97739809e-03,\n",
       "       -2.50325967e-02,  3.94218117e-02,  2.20866427e-02, -6.96355626e-02,\n",
       "       -1.84363667e-02,  6.47622943e-02, -3.19238529e-02, -3.34458717e-04,\n",
       "       -9.44131315e-02, -2.75535546e-02,  9.37956497e-02, -3.97172421e-02,\n",
       "       -5.48244640e-02, -7.35982433e-02,  3.06716226e-02, -1.83581058e-02,\n",
       "       -3.45700011e-02, -8.68977979e-02,  3.77518032e-03,  5.92463985e-02,\n",
       "       -2.48443037e-02,  3.90309952e-02,  5.73246032e-02,  6.93948045e-02,\n",
       "       -1.52991069e-02,  1.81229915e-02, -5.70868962e-02,  1.63580161e-02,\n",
       "        4.99555990e-02,  4.71493714e-02, -5.45823574e-03, -4.61004190e-02,\n",
       "        2.65028269e-04,  3.28978263e-02,  3.27535272e-02, -4.61923052e-03,\n",
       "       -5.02222404e-02,  1.16228238e-02,  9.94491857e-04, -1.82381843e-03,\n",
       "        1.22644603e-02,  4.89323847e-02,  1.92849077e-02, -3.05132568e-02,\n",
       "        6.91165328e-02,  5.40886335e-02,  3.33432853e-02,  1.76148210e-02,\n",
       "       -7.94605985e-02, -1.55845354e-03,  2.64863926e-03, -3.93628962e-02,\n",
       "       -9.06160288e-03, -2.21789591e-02,  7.00253919e-02, -5.39434515e-02,\n",
       "        2.51172023e-04,  8.13577045e-03,  2.11066697e-02, -1.22434311e-02,\n",
       "        2.50195665e-03, -7.75393546e-02, -3.07539925e-02, -3.85862775e-02,\n",
       "       -2.60315239e-02, -7.26601155e-03, -4.74035628e-02,  2.74925604e-02,\n",
       "        6.27044290e-02,  1.21729849e-02, -9.00995806e-02,  7.01986020e-03,\n",
       "       -7.25175738e-02,  3.95752601e-02,  2.65528094e-02, -1.65148024e-02,\n",
       "       -6.95326328e-02,  2.03166306e-02, -1.73326395e-02, -1.30853672e-02,\n",
       "       -3.04353498e-02, -8.10760781e-02, -2.38413047e-02,  3.72921377e-02,\n",
       "       -2.87856963e-02, -3.34480554e-02, -1.17994342e-02,  1.54691944e-02,\n",
       "        4.38725688e-02, -3.99973691e-02,  1.70276612e-02,  1.43837035e-02,\n",
       "       -3.98151986e-02,  7.29799923e-03,  3.04173883e-02, -1.05751446e-02,\n",
       "        3.36092301e-02, -4.17916961e-02, -1.81869697e-02, -4.83127199e-02,\n",
       "        1.16120735e-02,  1.27307931e-02,  1.66809987e-02,  4.98292632e-02,\n",
       "       -4.74931933e-02, -2.19929088e-02,  6.33655563e-02,  4.39752378e-02,\n",
       "       -5.17869974e-03, -1.67591181e-02, -5.59375994e-03, -3.40021332e-03,\n",
       "       -4.56669964e-02,  2.92750578e-02,  1.18575720e-02,  1.85131989e-02,\n",
       "        5.46848495e-03,  3.92383710e-02, -3.70506980e-02,  4.75206785e-02,\n",
       "       -2.11520214e-02,  5.91266202e-03,  1.17902821e-02, -2.90538743e-02,\n",
       "        4.72756959e-02, -8.20420459e-02,  2.50598304e-02, -6.57238141e-02,\n",
       "       -4.06940468e-02,  8.11182801e-03,  5.48868859e-03,  6.46279523e-06,\n",
       "       -4.75646928e-03, -4.26454805e-02, -8.75814725e-03, -3.86060849e-02,\n",
       "       -4.50111888e-02, -8.44265595e-02,  1.68802962e-02, -3.89397405e-02,\n",
       "        3.91559117e-02,  1.20103033e-02,  1.73874740e-02,  1.37300327e-01,\n",
       "       -2.14617904e-02,  4.19951528e-02, -5.10522537e-02, -2.43799221e-02,\n",
       "        3.83415595e-02, -2.53898297e-02, -2.64205690e-02, -9.14482342e-04,\n",
       "        5.46156056e-02, -8.24305601e-03,  2.98091490e-02, -1.71498321e-02,\n",
       "       -5.12973815e-02,  5.19833565e-02, -6.48108199e-02,  1.77301820e-02,\n",
       "       -6.00340329e-02, -1.62178403e-04,  4.55418639e-02,  3.35992337e-03,\n",
       "        1.69887152e-02,  2.68126391e-02,  7.69403651e-02,  1.34020792e-02,\n",
       "        7.66800418e-02,  2.68729124e-02,  4.96800914e-02,  5.05699739e-02,\n",
       "        1.54737784e-02, -2.40312349e-02,  4.40740548e-02,  7.54246935e-02,\n",
       "        1.50816492e-03,  3.82361673e-02, -5.38608208e-02, -9.58227366e-03,\n",
       "       -4.72265901e-03,  9.66127962e-03,  4.72241901e-02,  4.99569401e-02,\n",
       "        7.49747269e-04, -5.16482666e-02,  1.18834656e-02, -1.46977212e-02,\n",
       "        3.44635434e-02, -4.40268293e-02, -6.13335334e-03,  2.75066290e-02,\n",
       "        3.81692909e-02, -1.57661969e-03, -1.55550791e-02, -4.45982777e-02,\n",
       "        7.20721995e-03,  5.42309554e-03,  1.67904864e-03,  1.90243237e-02,\n",
       "        4.57566185e-03, -5.25892377e-02, -3.07379607e-02,  5.41666485e-02,\n",
       "       -2.15069228e-03,  4.74131890e-02,  1.12781655e-02, -4.67899814e-03,\n",
       "       -4.91881408e-02,  1.45098083e-02, -2.64245812e-02,  1.39935426e-02,\n",
       "       -1.19303605e-02, -2.84957532e-02,  1.85854211e-02,  1.93475168e-02,\n",
       "        7.75231495e-02, -1.35531812e-03, -4.11308259e-02,  1.30571574e-02,\n",
       "       -2.42009163e-02,  4.38355953e-02, -6.40684739e-03,  2.93477252e-02,\n",
       "        2.85069621e-03, -2.99038738e-02,  5.30754812e-02, -6.36051642e-03,\n",
       "       -2.75065973e-02, -1.74251217e-02,  2.98723811e-03,  2.49823779e-02,\n",
       "        5.59398085e-02, -1.00093540e-02, -2.34275945e-02, -5.13297208e-02,\n",
       "       -2.83708330e-02, -6.88044913e-03,  1.52647905e-02,  1.41951451e-02,\n",
       "       -5.31074184e-04, -2.43578851e-03, -2.18985230e-03, -6.48255721e-02,\n",
       "        6.25754446e-02, -4.93846796e-02,  4.67386171e-02,  1.30434809e-02,\n",
       "       -4.79739532e-03,  9.08996910e-03,  3.22848819e-02, -2.82868575e-02,\n",
       "        2.14853827e-02, -5.94309531e-02, -3.30015682e-02, -3.33171710e-02,\n",
       "       -2.11092364e-02, -5.06853610e-02,  2.22479776e-02,  1.33110071e-02,\n",
       "        3.61178331e-02,  1.61236022e-02, -4.60449457e-02,  1.19608492e-02,\n",
       "       -5.61657138e-02,  1.84587613e-02,  3.80514972e-02,  2.93533206e-02,\n",
       "        1.98935857e-03, -3.98888998e-02,  4.66084806e-03,  5.87726338e-03,\n",
       "       -1.81128122e-02,  2.02915892e-02,  1.94011554e-02, -1.08440313e-02,\n",
       "       -3.59798670e-02, -3.22365854e-03,  1.04957959e-02, -1.36667602e-02,\n",
       "        3.04718614e-02,  1.90530941e-02,  1.73853077e-02,  1.16222845e-02,\n",
       "        9.77598578e-02, -2.97668967e-02, -2.25309823e-02, -1.26916496e-02,\n",
       "        1.34985242e-02,  4.97255176e-02,  3.15608853e-03, -1.86445210e-02,\n",
       "       -5.06685525e-02,  8.09740368e-03, -2.94191334e-02,  6.01431951e-02,\n",
       "        7.92032387e-03, -4.45923507e-02, -7.37761939e-03, -3.95057462e-02,\n",
       "       -7.28001222e-02, -8.26678984e-03, -2.29492486e-02, -3.07768676e-02,\n",
       "       -6.79395022e-03, -3.14479955e-02,  2.67259181e-02, -6.32327283e-03,\n",
       "       -1.38436649e-02,  3.63875628e-02,  5.44144725e-03,  5.94752692e-02,\n",
       "        1.87046379e-02,  1.08095054e-02,  1.48030380e-02,  7.80095300e-03,\n",
       "        5.29955998e-02,  4.62095030e-02, -2.20073573e-02,  4.07381095e-02,\n",
       "       -4.27294150e-02, -2.43479144e-02,  1.49267642e-02,  1.40717095e-02,\n",
       "       -4.14645486e-02,  6.59813592e-03, -1.97561383e-02, -1.13537302e-02,\n",
       "       -3.53967473e-02, -1.02605240e-03, -4.93127517e-02,  6.61688522e-02,\n",
       "       -8.87261238e-03,  2.35988833e-02,  1.06026493e-01,  2.26850435e-02,\n",
       "       -2.28102002e-02,  2.31238548e-02, -1.37511631e-02,  8.11582524e-03,\n",
       "       -1.57960001e-02, -1.61505770e-02,  4.70435917e-02,  3.38901579e-02,\n",
       "       -6.42819256e-02,  2.68825274e-02,  4.46762852e-02, -5.37827387e-02,\n",
       "        1.34859020e-02,  1.12940250e-02, -1.19152796e-02,  2.25686263e-02,\n",
       "       -6.60741478e-02, -1.70281017e-03,  1.12037994e-02,  6.63324550e-04,\n",
       "        1.34792393e-02,  9.20805484e-02, -1.06241349e-02, -2.22006720e-02,\n",
       "        7.09915394e-03, -6.97633717e-03,  7.77507201e-02,  3.24934791e-03,\n",
       "       -2.28444934e-02, -5.47552854e-02, -2.72729676e-02, -2.54264829e-04,\n",
       "       -2.24407972e-03,  1.71713140e-02,  1.27546601e-02, -3.29916812e-02,\n",
       "       -1.21774394e-02,  4.47324291e-02, -1.13665210e-02, -1.77041795e-02,\n",
       "       -7.78539181e-02,  2.86748651e-02,  5.23599498e-02,  1.43966610e-02,\n",
       "        1.29870896e-03, -1.26846358e-02,  6.01037173e-03, -3.57662328e-02,\n",
       "       -2.20903140e-02, -3.51163782e-02,  3.37327272e-02,  2.02087983e-02,\n",
       "        7.90981855e-03, -7.60582043e-03, -6.04353994e-02, -1.07619502e-01,\n",
       "       -5.88327982e-02,  1.20881675e-02, -1.93461813e-02, -4.39521484e-02,\n",
       "        1.64439566e-02,  1.99242234e-02,  5.19761024e-03,  3.38200363e-03,\n",
       "        3.53448130e-02, -2.57639736e-02, -2.08360348e-02, -4.86890711e-02,\n",
       "       -1.51020316e-02, -1.23865185e-02,  4.05044900e-03,  4.32309173e-02,\n",
       "       -2.29573138e-02,  1.99500769e-02,  7.16117173e-02,  3.15544792e-02,\n",
       "        3.91772874e-02, -1.11699902e-01,  3.17927040e-02, -1.12867234e-02,\n",
       "        2.52075419e-02,  1.97079834e-02, -9.73269064e-03,  1.70829091e-02,\n",
       "       -7.32486770e-02, -4.49189777e-03,  2.30373591e-02, -7.05214068e-02,\n",
       "        8.40082467e-02, -4.82462905e-02, -5.11029698e-02, -8.90308153e-03,\n",
       "       -3.73940207e-02, -1.10806152e-02, -6.48099650e-03,  2.32252441e-02,\n",
       "       -2.40092594e-02, -1.11650288e-01, -4.43916768e-02, -1.69524290e-02,\n",
       "       -1.19974073e-02,  6.24316707e-02, -2.23387480e-02,  1.50784722e-03,\n",
       "       -3.66732199e-03,  7.71294627e-03, -6.01380179e-03, -1.66784171e-02,\n",
       "       -2.73071658e-02,  3.14585306e-02, -1.53114060e-02, -2.44928524e-02,\n",
       "       -5.30277146e-03, -3.00243776e-02,  1.60603616e-02,  1.63635676e-04,\n",
       "       -4.58465852e-02, -9.72599089e-02,  2.23859772e-02,  2.63230465e-02,\n",
       "        6.49596704e-03, -8.88681330e-04,  1.01076076e-02,  2.85074729e-02,\n",
       "       -1.06234429e-02, -3.18104494e-03, -7.35824462e-03,  4.36278060e-03,\n",
       "       -3.02603710e-02, -8.11630301e-03,  7.84110371e-03, -1.13554029e-02,\n",
       "       -3.09896749e-02, -4.53476154e-04, -3.97020988e-02,  1.08360194e-01,\n",
       "       -3.67919467e-02,  2.29449645e-02,  3.28626335e-02, -9.37714577e-02,\n",
       "        2.52908338e-02, -2.36387048e-02, -5.68382489e-03, -2.78829364e-03,\n",
       "        1.49427913e-02,  2.65917480e-02, -7.26297451e-03, -1.53669259e-02,\n",
       "        1.10936549e-03,  3.37384120e-02,  4.70681190e-02,  1.29410625e-02,\n",
       "        2.02180333e-02, -3.16690393e-02,  6.44986751e-03,  9.63122002e-04,\n",
       "       -2.43475921e-02,  5.24180084e-02, -1.00819152e-02,  3.04481275e-02,\n",
       "        2.08840636e-03, -2.97336765e-02,  1.40583108e-03, -6.63226983e-03,\n",
       "        5.89024089e-02, -1.51539482e-02,  7.61142373e-02, -4.84904042e-03,\n",
       "       -1.32768713e-02, -9.03798416e-02, -1.76527742e-02,  1.63121186e-02,\n",
       "        1.95579082e-02, -2.17949431e-02, -3.28274481e-02, -6.90052726e-33,\n",
       "       -6.20699907e-03,  8.62388499e-03, -1.83469744e-03, -4.74410653e-02,\n",
       "       -5.98169528e-02, -1.91761162e-02,  3.57440338e-02,  7.23051727e-02,\n",
       "        9.31614488e-02,  7.86619354e-03, -2.70304806e-03, -2.68986402e-03,\n",
       "        1.22554619e-02, -5.75526828e-05,  5.76830050e-03,  5.53852820e-04,\n",
       "       -1.05994651e-02,  1.41872829e-02,  1.28120631e-02, -7.30436072e-02,\n",
       "       -1.53569402e-02,  4.52658022e-03, -2.28271745e-02,  2.46334001e-02,\n",
       "       -3.16048898e-02,  1.91361306e-03, -2.03359015e-02, -4.04604152e-02,\n",
       "        7.73352152e-03,  1.17164310e-02, -2.39449833e-02, -5.83028561e-03,\n",
       "        2.15026233e-02, -3.68135013e-02, -4.07864153e-03,  9.90722477e-02,\n",
       "        2.58106925e-02,  5.32198250e-02, -5.80829429e-03, -3.33857932e-03,\n",
       "       -3.72946291e-04, -9.79696289e-02,  2.62480378e-02, -2.25385334e-02,\n",
       "        1.83571745e-02, -6.51343202e-04,  6.95784437e-03,  1.99724697e-02,\n",
       "        7.20504019e-03, -1.55118452e-02, -4.33274582e-02, -3.43151316e-02,\n",
       "        6.95383002e-04, -3.35822962e-02, -3.33628319e-02,  2.99683288e-02,\n",
       "       -2.57846192e-02, -4.54449765e-02, -1.12605828e-03,  2.41483804e-02,\n",
       "       -7.89461751e-03,  4.99777533e-02, -4.24790122e-02,  4.15840372e-02,\n",
       "       -1.45307779e-02,  2.13534082e-03,  2.19061016e-03, -2.69758180e-02,\n",
       "       -4.41539548e-02,  3.51737365e-02,  2.08834410e-02,  3.13814133e-02,\n",
       "        3.20678279e-02,  6.45062933e-03,  4.81016003e-02, -7.96223059e-02,\n",
       "       -4.66898493e-02,  4.00343910e-03, -2.96775736e-02, -2.71991566e-02,\n",
       "       -3.57914530e-02, -3.56690306e-03, -4.19228896e-02,  2.22711992e-02,\n",
       "        1.04760649e-02,  3.24688703e-02,  4.01979052e-02,  3.45999673e-02,\n",
       "       -3.14292684e-03,  1.38666052e-02,  2.23327149e-02, -3.19530442e-02,\n",
       "       -2.02560239e-02, -1.39420328e-03,  3.84180881e-02,  1.28898909e-02,\n",
       "       -3.92672460e-04,  3.00178374e-03, -9.95360594e-03,  2.13763788e-02,\n",
       "       -1.93240726e-03,  1.87900271e-02, -4.27908301e-02,  1.53824864e-02,\n",
       "        1.68700852e-02, -1.71813089e-02, -6.33929158e-03, -2.77774148e-02,\n",
       "       -3.22784893e-02,  5.03702872e-02, -3.23612764e-02, -3.44391866e-03,\n",
       "       -9.99063253e-03, -8.43620449e-02,  4.87176180e-02, -3.24063115e-02,\n",
       "        5.40617527e-03,  5.51001467e-02, -5.40288053e-02, -8.30353126e-02,\n",
       "        3.38025056e-02,  3.79092470e-02,  3.07564791e-02, -2.18308922e-02,\n",
       "       -2.84309536e-02,  2.21292265e-02,  3.60208787e-02,  1.63009800e-02,\n",
       "       -2.96828747e-02, -6.12884089e-02, -9.45448689e-03,  5.25470264e-02,\n",
       "        2.64113510e-07, -2.94026248e-02, -5.38795348e-03, -2.39211507e-02,\n",
       "        2.97186780e-03,  1.21479016e-03,  3.90218683e-02, -2.91405767e-02,\n",
       "        3.08625121e-02, -4.16087471e-02,  6.18621372e-02, -1.80313233e-02,\n",
       "        5.38680442e-02, -2.68559568e-02,  4.38041650e-02,  5.36045656e-02,\n",
       "       -3.81182730e-02,  1.15937619e-02, -3.06084473e-03, -1.04644904e-02,\n",
       "       -2.82597635e-02, -1.82387717e-02,  3.37533429e-02, -4.15378921e-02,\n",
       "       -7.68043828e-05,  4.11796607e-02,  2.79835258e-02,  2.55445410e-02,\n",
       "        2.86542270e-02,  4.41146009e-02, -2.70021036e-02, -2.24231016e-02,\n",
       "        1.99877042e-02, -1.50444712e-02, -1.65931173e-02, -4.53702686e-03,\n",
       "       -2.55646999e-03,  3.61791858e-03,  7.86218494e-02,  3.56825739e-02,\n",
       "        2.92200521e-02, -1.53348250e-02,  6.16726317e-02, -3.02549475e-03,\n",
       "        4.70018685e-02,  2.64080092e-02,  1.30914217e-02,  6.61343634e-02,\n",
       "        7.91021623e-03,  1.19472155e-02,  2.69904044e-02, -4.22831550e-02,\n",
       "        1.91731006e-02, -1.98851600e-02,  2.34962739e-02,  1.44265117e-02,\n",
       "       -2.94213593e-02, -1.12288194e-02, -5.04069775e-02,  1.70318950e-02,\n",
       "       -1.05148396e-02,  2.62144431e-02, -1.11104334e-02, -1.79752726e-02,\n",
       "        1.14878796e-01,  1.97081733e-02, -2.35284567e-02, -2.77423393e-02,\n",
       "        1.29396513e-34, -9.73453000e-03, -4.34227288e-03, -1.07864700e-02,\n",
       "        2.01473627e-02,  3.24909505e-03,  2.68271845e-02, -1.27398623e-02,\n",
       "        3.57468314e-02,  1.28942635e-02,  6.35127723e-02,  2.06900910e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a77ce7b9-2f7c-4ebb-9973-93ce54d1525d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b9c0ae2-7725-45b1-aeee-05d35c3c0849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in ./.venv/lib/python3.11/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./.venv/lib/python3.11/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim) (1.17.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"gensim\" \"numpy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27457d47-3644-4657-b3e2-9c78ca5dcff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mapi\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglove-wiki-gigaword-50\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mmost_similar([model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mking\u001b[39m\u001b[38;5;124m'\u001b[39m]], topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/research2025/LLMs/.venv/lib/python3.11/site-packages/gensim/__init__.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/research2025/LLMs/.venv/lib/python3.11/site-packages/gensim/corpora/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/research2025/LLMs/.venv/lib/python3.11/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[1;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[0;32m~/Documents/research2025/LLMs/.venv/lib/python3.11/site-packages/gensim/interfaces.py:19\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[1;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[0;32m~/Documents/research2025/LLMs/.venv/lib/python3.11/site-packages/gensim/matutils.py:1034\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(set1 \u001b[38;5;241m&\u001b[39m set2)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(union_cardinality)\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;66;03m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlogsumexp\u001b[39m(x):\n",
      "File \u001b[0;32m~/Documents/research2025/LLMs/.venv/lib/python3.11/site-packages/gensim/_matutils.pyx:1\u001b[0m, in \u001b[0;36minit gensim._matutils\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-wiki-gigaword-50\")\n",
    "model.most_similar([model['king']], topn=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c2579e1-89d1-4bf1-8932-e82a49ed16ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"pandas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff0ce5b9-c97e-490d-84e5-afbc33306d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib import request\n",
    "\n",
    "data = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/train.txt')\n",
    "lines = data.read().decode(\"utf-8\").split(\"\\n\")[2:]\n",
    "\n",
    "playlists = [s.rstrip().split() for s in lines if len(s.split()) > 1]\n",
    "songs_file = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/song_hash.txt')\n",
    "songs_file = songs_file.read().decode(\"utf-8\").split('\\n')\n",
    "songs = [s.rstrip().split('\\t') for s in songs_file]\n",
    "songs_df = pd.DataFrame(data=songs, columns=['id', 'title', 'artist'])\n",
    "songs_df = songs_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edc2ca6a-ccc6-4598-ba9f-840b9f301b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist #1:\n",
      " ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '2', '42', '43', '44', '45', '46', '47', '48', '20', '49', '8', '50', '51', '52', '53', '54', '55', '56', '57', '25', '58', '59', '60', '61', '62', '3', '63', '64', '65', '66', '46', '47', '67', '2', '48', '68', '69', '70', '57', '50', '71', '72', '53', '73', '25', '74', '59', '20', '46', '75', '76', '77', '59', '20', '43'] \n",
      "\n",
      "Playlist #2:\n",
      " ['78', '79', '80', '3', '62', '81', '14', '82', '48', '83', '84', '17', '85', '86', '87', '88', '74', '89', '90', '91', '4', '73', '62', '92', '17', '53', '59', '93', '94', '51', '50', '27', '95', '48', '96', '97', '98', '99', '100', '57', '101', '102', '25', '103', '3', '104', '105', '106', '107', '47', '108', '109', '110', '111', '112', '113', '25', '63', '62', '114', '115', '84', '116', '117', '118', '119', '120', '121', '122', '123', '50', '70', '71', '124', '17', '85', '14', '82', '48', '125', '47', '46', '72', '53', '25', '73', '4', '126', '59', '74', '20', '43', '127', '128', '129', '13', '82', '48', '130', '131', '132', '133', '134', '135', '136', '137', '59', '46', '138', '43', '20', '139', '140', '73', '57', '70', '141', '3', '1', '74', '142', '143', '144', '145', '48', '13', '25', '146', '50', '147', '126', '59', '20', '148', '149', '150', '151', '152', '56', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '60', '176', '51', '177', '178', '179', '180', '181', '182', '183', '184', '185', '57', '186', '187', '188', '189', '190', '191', '46', '192', '193', '194', '195', '196', '197', '198', '25', '199', '200', '49', '201', '100', '202', '203', '204', '205', '206', '207', '32', '208', '209', '210']\n"
     ]
    }
   ],
   "source": [
    "print(\"Playlist #1:\\n\", playlists[0], '\\n')\n",
    "print(\"Playlist #2:\\n\", playlists[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5374bb-a84c-4e92-a776-a768f4b6615e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0578a026-215e-45a8-abef-fc0c237c621d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
